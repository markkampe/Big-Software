<html><head>

<title>Implementat & Test</title>
</head><body>
<center>
<a name="desc_4">
<h1>Project Phase 4<br>
</a>
Implementation and Testing Sprint
</h1>
</center>
<P>
The first three projects took us through all of the activities that precede
implementation.  In this final project you will actually implement the components
you designed in phase 3 ... and by now it should come as little surprise to you
that only part of your time will be spent coding, and (if you do it right) very 
little of your time will be spent debugging.
</P>

<table align="center" border="1" cellpadding="5" cellspacing="0">
<tbody>
  <tr>
	<th>Phase</th>
	<th>Assignment</th>
	<th>Value<sup>3</sup></th>
  </tr>

  <tr>
	<td rowspan="7">4</td>
	<td> <A href=#desc_4.1>Final Code</a> (individual)</td>
	<td> 20 </td>
  </tr>
  <tr>
	<td> <A href=#desc_4.2>Pair Programming Exercise and Report</a> </td>
	<td> 10 </td>
  </tr>

  <tr>
	<td> <A href=#desc_4.3>Code Review Notes and Reports</a> (individual)</td>
	<td> 20 </td>
  </tr>

  <tr>
	<td> <A href=#desc_4.4>Test Driven Development Report</a> </td>
	<td> 10 </td>
  </tr>

  <tr>
	<td> <A href=#desc_4.5>Final Test Suite</a> </td>
	<td> 20 </td>
  </tr>

  <tr>
	<td> <A href=#desc_4.6>Sprint Review/Demo</a> </td>
	<td> 10 </td>
  </tr>

  <tr>
	<td> <A href=#desc_4pm>Post-Mortem Report</a> </td>
	<td> 10 </td>
  </tr>
</tbody>
</table>
<UL>
<sup>3</sup> less 10% for each <a href=#latepolicy>unexcused</a> late day.<br>
	<P>
	Each team member will use their code in one of the exercises
	(Pair Programming, Test Driven Development, or Code Review),
	and all team members will participate (as a submitter or reviewer)
	in at least one code review.  While most of these activities will involve selected
	individuals, you are encouraged to discuss each of these activities as a team,
	and the reports from most of those activities will be graded as team deliverables.
	<P>
	You may note that there is no management plan or grade associated with this
	project.  You should, by now be able to plan and coordinate activities for
	yourselves, and you are already being graded on your ability to deliver the 
	required work on schedule ... which is the point.
	</P>
</UL>

<a name="desc_4.1">
<H3>P4.1 Final Code</h3>
</a>
<P>
The primary activity in this project is for each person to implement
and test the component they designed in project 3.  There will be
many processes and exercises surrounding this implementation, but
the primary deliverable is working code that implements the requirements
and specifications set out in project 3.
</P>
<P>
Source files and instructions/scripts (e.g. ant/makefile) required to build them.
Make sure that you document the build environment that is required to build your
components, because part of your grade will depend on the TA being able to
independently build your product from the checked-in sources and instructions.
If this is not practical (e.g. because your component cannot be built on a Linux
system) make special arrangements with the TA to have him/her observe a check-out
build-from-scratch.
</P>
<P>
You should also re-submit the
specifications and design for this component (from project 3)
with any changes you have made since then.
</P>
<P>
Each code submission be graded on the basis of:
<ul>
	<li> 10% appropriateness of chosen languages, middleware, and tools.</li>
	<li> 20% completeness relative to project 3 design and specifications</li>
	<li> 20% how well it corresponds to the (revised) design</li>
	<li> 20% code quality (use of language features, simplicity, efficiency)</li>
	<li> 20% code understandability (structure, layout, comments)</li>
	<li> 10% grader is able to build it from source</li>
</ul>
<P>
After you have completed all of your implementation and testing, and
you believe your code is entirely complete, fill out a
<a href="#submission">standard submission form</a>
and e-mail it to the submission alias.
</P>

<a name="desc_4.2">
<H3>P4.2 Pair Programming Exercise</h3>
</a>
<P>
At least one member of the team will ask another member to join
them for at least one pair-programming session.  How you divide
up your effort (think/code, code/review, code/test) is entirely
up to you, and you are welcome to try various approaches.
</P>
<P>
For all work done in a pair-programming mode, the commit comments
made during those sessions should reflect the division of 
responsibilities under which that work was done.
</P>
<P>
NOTE: what ever component this is done for should not also be used
for code review or Test Driven Development.
</P>
<P>
After the end of each pair-programming session, each of the
people involved should jot down notes on what happened.  After
the component has been completed, the two people should get
together (ideally discussing it with the entre team) and 
write up a report on the experience.  This report should cover:
<UL>
   <li>	what role divisions you tried and how you decided how to organize those activities.</li>
   <li> how effectively each persons time was used (with each division of roles).</li>
   <li> the speed of code development, vs working alone.</li>
   <li> the quality of the code, vs working alone.</li>
   <li> pleasant or unpleasant aspects of the experience.</li>
   <li> how you would do this differently next time.</li>
</UL>
</P>
<P>
This activity and report be graded on the basis of:
<ul>
	<li> 20% documentation of collaboration in commit comments</li>
	<li> 20% reasonable role divisions, reasonably carried out</li>
	<li> 20% amount of work accomplished in this mode</li>
	<li> 20% quality of work accomplished in this mode</li>
	<li> 20% reasonable insights into the process</li>
</ul>

When you are ready to submit this report for grading, fill out a
<a href="#submission">standard submission form</a>
and e-mail it to the submission alias.
</P>
<UL>
	It will make the grader's job much easier if you can refer us
	to specific commits done during the pair programming sessions.
</UL>

<a name="desc_4.3">
<H3>P4.3 Code Review</h3>
</a>
<P>
At least one member of the team will write all of his/her code,
and <strong>before</strong> running test suites against it, submit that code for
review by the other members of their team.  
The other team members
will study the code, prepare, nodes and conduct a formal code review,
producing a report with must-fix/should-fix/advice items.
The author will make the appropriate revisions, and then move on
to testing.  After the code is working, the author will discuss
the process with the rest of the team and then write
up a report on the process.
<UL>
	<P>
	The author will prepare a review package containing the component 
	requirements, specifications, and design (perhaps modified) from project 3, 
	and the implementing code.
	</P>
	<P>
	Each of the other team members will review that package and prepare
	written notes, which will be checked in to github 
	<strong>well prior</strong> to the review.
	</P>
	<P>
	After the review, a formal report will be prepared (listing all important
	conclusions) and checked in to github.
	</P>
	<P>
	The author will address all of the raised issues, and then complete the
	testing.
	</P>
</UL>
<P>
NOTE: What ever component this is done for should not also be used for
TDD or pair programming.
</P>
<P>
The author's review report should include (in addition to the usual information):
<UL>
   <LI>	how valuable the input received from the code review process was, 
  	and what kinds of problems it turned up.</li>
   <li> what kinds of problems remainined in the code after the code
	review process, and why they weren't found.</li>
   <li> the relative merits of doing code review before or after testing.</li>
   <li> would knowing that you were going to have a code review have
     	caused you to make any changes to your test plan?</li>
   <LI> how would you do this differently next time?</li>
</UL>

<P>
The grading of the reviewer's submissions will be based on:
<ul>
	<li> 10% notes: submitted well before scheduled review</li>
	<li> 40% notes: thoroughness of study to which they attest</li>
	<li> 5% notes: articulation and organization of issues</li>
	<li> 5% notes: comments appropriate and within scope</li>
	<li> 15% report: completness with respect to issues raised</li>
	<li> 10% report: clear disposition of every issue</li>
	<li> 10% report: issue clarity</li>
	<li> 5% report: all comments appropriate and within scope</li>
</ul>

The grading of the author's submissions will be based on:
<ul>
   <li> 10% review package: adequate background</li>
   <li> 20% review package: clarity of requirements, specifications, design</li>
   <li> 20% review package: code quality</li>
   <li> 10% review package: code understandability</li>
	
   <li> 20% report: code improvement value extracted from the review process</li>
   <li> 20% report: insights gained from the process</li>
</ul>

<P>
When you have your code package ready for review, fill out a 
<a href="#submission">standard submission form</a>
and e-mail it to the submission alias.
</P>
<P>
Each team member should check their review notes into github as soon
as they are ready.  After the review has been completed and the final
report written, it too should be checked into github.  Fill out a
<a href="#submission">standard submission form</a>
and e-mail it to the submission alias.
</P>
<P>
After the code is working the author should prepare a report on the
review process and the value it added, and then fill out a
<a href="#submission">standard submission form</a>
and e-mail it to the submission alias.
</P>

</PRE>

<a name="desc_4.4">
<H3>P4.4 Test Driven Development</h3>
</a>
<P>
At least one member of the team will use Test Driven Development to
implement his/her component, building and running the test cases for 
each increment of code as the new code is added.   The rewards for 
this approach should be:
<OL type="a">
   <LI> the there should be little debugging to do, and what little 
	there is should be quite simple.</li>
   <LI>	by the time the coding is done, most of the testing will also be done.</li>
</OL>
But it will require the test framework to be working first, and more up-front 
planning about the order in which things should be implemented.  Check in this
plan before you start coding.  There are a few tricks to this planning:
<UL>
   <LI> there is a natural order to implementation and testing, because
        some features fundamentally depend on others.  These dependencies
        must be recognized.</li>
   <LI> some test cases may be only applicable to incomplete code
	and become obsolete after the code has been completed.  These
	represent a waste of work and should be avoided as much as
	possible.</li>
</UL>
<P>
As evidence that you did infact follow a TDD process, and for keeping a
record of the problems found, please:
<UL>
   <LI> commit the new code and associated test cases together,
        before running them.</li>
   <LI> after you have passed the tests, commit the updated code
        and test cases (again together), with comments describing
        the problems found and fixed during the testing.  If they
	worked first time (this will happen) follow this up with
	a trivial commit and a comment to that effect.</li>
   <LI> do not move on to implementing new functionality until
	you have passed all the tests for the existing functionality.</li>
</UL>
<P>
NOTE: What ever component this is done for should not also be used for
code review or pair programming.
<P>
After completing development, the/each person who uses this methodology
will discuss the experience with the team and write a brief report, covering 
what they did, and specifically addressing the following questions:
<UL>
   <LI>	how the implementation order was decided, and how that order worked.</li>
   <LI> the efficiency of the process was (e.g. how much time went into building
 	test cases that were only useful during the construction process).</li>
   <LI> to what extent do you believe that knowing how you were going to
	test the code caused you to write code that was more correct?</li>
   <LI> were there bugs that showed up later that were not found by the
	TDD process?  If so, why do you think they were not turned up
	earlier?</li>
   <LI> how would you do this differently next time?</li>
</UL>

<P>
This activity and report be graded on the basis of:
<ul>
   <li>	10% a reasonable plan for implementation order (checked in before starting)</li>
   <li> 30% tests were written and passed incrementally (from the commit history)</li>
   <li> 20% each test meaningfully validated the associated code (from the commit history)</li>
   <li> 20% automation framework enabled testing from the start</li>
   <li>	20% reasonable insights gained from the process</li>
</ul>
<P>
After you have completed your report, check it in to github, fill out the
<a href="#submission">standard submission form</a>
and e-mail it to the submission alias.
</P>
<P>
It will make things much easier on the graders if you list the commits
that represent each increment of functionality and the associated tests.
</P>
<a name="desc_4.5">
<H3>P4.5 Final Test Suite</h3>
</a>
<P>
Each team member will, for his/her component, implment the 
test plan proposed in project 3, and run those tests against
their component implementation.
</P>
<P>
The execution of your test cases should be automated (e.g. so that
all tests can be run with a single command), and all of the test
cases and scripts should be checked in to git-hub.  
Make sure that you document the environment and procedure for running
these tests, because part of your grade will depend on the TA being able to
independently test your product from the checked-in sources and instructions.
If this is not practical (e.g. because your component cannot be tested on a Linux
system) make special arrangements with the TA to have him/her observe a check-out
build-and-test-from-scratch.
</P>
<P>
Each team member should submit:
<UL>
   <LI>	a reference to your (perhaps updated) test plan from project 3.</li>
   <LI>	the code that implements your test suite (and tools you needed to build).</li>
   <LI>	the output of having run that test suite against your component.</li>
</UL>
<P>
It is quite likely that you will, as a result of lessons learned during 
the implementation, decide you want to change your test plan.  If this
happens (a) update your project 3 test plan and (b) submit a summary of
and explanations for the changes.
</P>
<P>
This activity and report be graded on the basis of:
<ul>
	<li> 20% completeness relative to project 3 test plan</li>
	<li> 20% does the program pass the test suite</li>
	<li> 10% tests: implementation code quality</li>
	<li> 10% tests: readability</li>
	<li> 10% choice and exploitation of automation framework</li>
	<li> 10% automated test execution and pass determination</li>
	<li> 10% clarity of tests run and pass/fail indications</li>
	<li> 10% grader is able to run and pass test suite</li>
</ul>

<P>
When you are ready to submit this package for grading, fill out a
<a href="#submission">standard submission form</a>

<a name="desc_4.6">
<H3>P4.6 Sprint Review/Demo</h3>
</a>
<P>
You have built your components, and your test suite, and you have
run your tests.  Hopefully you have been able to combine your
components and demonstrate functionality for the integrated whole.
Now it is time for you to review what you have produced with your
product owner.
At the end of each SCRUM sprint, the team presents the work that was
completed during that sprint to the product owner.  This is, in part,
ceremonial (the team can claim success and receive feedback on the
work they have completed) but it also a very practical sign-off:
<UL>
    <LI> the team briefly reviews the requirements to have been
	 met and demonstrates that the product now meets them.</li>
    <LI> the team overviews the testing that has been done.</li>
    <LI> the product owner decides whether or not this work
         has actually been completed (i.e. deliverable
         functionality).</li>
    <LI> velocity points are earned for accepted work.</li>
</UL>

<P>
Your review presentation should include:
<UL>
   <LI>	a brief summary of the functionality of each of the components
	built during this sprint and the (component level) requirements
	it was to meet.</li>
   <LI>	a brief overview of the scope of the automated testing plan for
	each component.</li>
   <LI>	a brief overview of the expected functionality of the integrated
	pieces.</li>
   <LI>	a demonstration of a check-out from git-hub and (error-free) 
	build and automated test of each component (according to that test plan).</li>
   <LI>	a demonstration of the functionality of the combined pieces,
	showing them working together, and that all (applicable) key 
	requirements have been met.</li>
   <LI> a summary of what progress this represents towards the construction
	of your larger project (what this means and what comes next).</li>
</UL>
<P>
This is not a long presentation (4-5 minutes will be fine).  
It might be useful to have slides to cover the components, 
their requirements, and their test plans, but this is not
necessary. 
</P>
<P>
This presentation be graded on the basis of:
<ul>
	<li> 10% overview of components and their requirements</li>
	<li> 10% overview of component test plans</li>
	<li> 10% overview of integration and resulting functionality
	         of the combined sub-components.</li>
	<li> 20% error free check-out and build from scratch</li>
	<li> 20% error free check-out and execution of all test cases</li>
	<li> 20% demo shows component meets all of its key functional requirements</li>
	<li> 10% demo shows clear evidence of successful integration
	         (that all sub-components are clearly interoperating).</li>
</ul>
<P>
When you have an idea when you will be ready for your review, 
contact either the professor or the Grutor to schedule it.

<a name="desc_4pm">
<H3>P4.7 Post-Mortem Report</H3>
</a>
<P>
This project is a learning exercise, and one of the major ways
we learn is by analyzing past mistakes.  You will, as a team,
review all aspects of this project.  One of you will then 
summarize that process into a post-mortem analysis report.
</P>
<P>
A report, summarizing the key issues raised in your post-mortem,
and the conclusions you came to.  Your post-mortem discussion 
should include:
<ul>
	<li> the implementation of your component design and the resulting code quality</li>
	<li> the implementation of your test plan, the problems found, and the confidence gained</li>
	<li> the relative efficacy of the competing development processes</li>
	<li> the integration of your components together</li>
	<li> the preparation of the release review/demo</li>
	<LI> the overall project as an educational exercise</li>
</ul>
</p>
<P>
This report be graded on the basis of:
<ul>
	<li> 50% whether or not you meaningfully discuss each of the required activities.</li>
	<li> 20% whether or not you identify all of the important incidents.</li>
	<li> 30% the extent to which you are able to derive and articulate useful lessons
	     (and good future advice) from those experiences.</li>
</ul>
<P>
Upload the notes from your post-mortem discussion to github, and fill out a
<a href="#submission">standard submission form</a>
and e-mail it to the submission alias.
</body></html>
